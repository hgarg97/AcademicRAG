# **AcademicRAG üß†üìö**

**AcademicRAG** is a Retrieval-Augmented Generation (RAG)-based chatbot designed to query and extract information from a vast collection of academic research papers. This project leverages **LangChain**, **Astra DB (Serverless Cassandra with Vector Search)**, **OpenAI LLMs**, and **Groq LLAMA 3.3** to build an intelligent research assistant. Additionally, we will be exploring **Agentic AI** methodologies to enhance response accuracy and contextual understanding.

---

## **üóÇ Project Structure**

The repository is structured as follows:

- **Main Directory:** Contains shared resources and configurations.
  - `.env` ‚Üí Stores environment variables like API keys.
  - `requirements.txt` ‚Üí Lists Python dependencies.
- **Datasets/** ‚Üí Contains research papers (excluded from Git).
- **Project Codebase:**
  - `create_vector_store.py` ‚Üí Extracts text from PDFs, splits content, and stores embeddings in Astra DB.
  - `app.py` ‚Üí Streamlit chatbot interface using LLAMA 3.3 and Astra DB vector retrieval.
  - `file-extraction.py` ‚Üí Moves all files from subdirectories to the main folder.

---

## **ü§ù Initial Setup**

### **1Ô∏è‚É£ Installing Anaconda and Setting Up the Environment**

To set up the Python environment, use Anaconda:

```bash
conda create -p venv python==3.10
```

- **Note**: `-p` creates the environment in the current directory.

Activate the environment:

```bash
conda activate venv/
```

or

```bash
conda activate /path/to/venv
```

---

### **2Ô∏è‚É£ Installing Dependencies**

Ensure you have all required dependencies installed:

```bash
pip install -r requirements.txt
```

#### **`requirements.txt` Includes:**

```txt
cassio
datasets
langchain
openai
tiktoken
streamlit
pymupdf
huggingface_hub
sentence-transformers
```

---

### **3Ô∏è‚É£ Setting Up Environment Variables**

#### **Option 1: Using a `.env` File**

Create a `.env` file and add:

```ini
ASTRA_DB_APPLICATION_TOKEN=<your_astra_db_token>
ASTRA_DB_ID=<your_astra_db_id>
OPENAI_API_KEY=<your_openai_api_key>
GROQ_API_KEY=<your_groq_api_key>
```

#### **Option 2: Setting Temporary Environment Variables**

For **Mac/Linux**:

```bash
export ASTRA_DB_APPLICATION_TOKEN="your_astra_db_token"
export ASTRA_DB_ID="your_astra_db_id"
export OPENAI_API_KEY="your_openai_api_key"
export GROQ_API_KEY="your_groq_api_key"
```

For **Windows** (Command Prompt):

```bash
setx ASTRA_DB_APPLICATION_TOKEN "your_astra_db_token"
setx ASTRA_DB_ID "your_astra_db_id"
setx OPENAI_API_KEY "your_openai_api_key"
setx GROQ_API_KEY "your_groq_api_key"
```

For **persistent storage** in Conda:

```bash
conda env config vars set ASTRA_DB_APPLICATION_TOKEN="your_astra_db_token"
conda env config vars set ASTRA_DB_ID="your_astra_db_id"
conda env config vars set OPENAI_API_KEY="your_openai_api_key"
conda env config vars set GROQ_API_KEY="your_groq_api_key"
conda env config vars list
```

---

## **üöÄ Running the AI Bot**

### **1Ô∏è‚É£ Extracting and Storing Research Papers in AstraDB**

Run the script to extract text from PDFs and store embeddings:

```bash
python create_vector_store.py
```

### **2Ô∏è‚É£ Running the Streamlit Chatbot**

Navigate to the project directory and execute:

```bash
streamlit run app.py
```

---

## **üî¨ Workflow Overview**

1Ô∏è‚É£ **Extract text from PDFs using `fitz` (PyMuPDF).**  
2Ô∏è‚É£ **Split the text into smaller chunks (800 tokens with 200 overlap) for efficient vector search.**  
3Ô∏è‚É£ **Embed text using HuggingFace Sentence Transformers (`all-MiniLM-L6-v2`).**  
4Ô∏è‚É£ **Store embeddings in AstraDB (Serverless Cassandra with vector search).**  
5Ô∏è‚É£ **Retrieve top 4 relevant documents based on similarity search.**  
6Ô∏è‚É£ **Use LLAMA 3.3 via Groq API to generate responses.**  
7Ô∏è‚É£ **Display responses in the Streamlit UI.**

---

## **üìå Future Enhancements**

- üìà Fine-tune retrieval for better accuracy.
- üõ†Ô∏è Experiment with **Agentic AI** for improved contextual reasoning.
- üì∫ Enhance UI with a more interactive research chatbot experience.

---

üí™ _Built with love for academic research!_
