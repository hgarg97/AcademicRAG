# ğŸ§  Retrieval-Augmented Generation (RAG) Chatbot for Academic PDFs

This project is a fully modular, class-based **RAG (Retrieval-Augmented Generation) system** that allows you to query a collection of academic **PDFs** and get contextual answers using **LLaMA 3.2 via Ollama**.

It integrates:

- Document preprocessing and intelligent **chunking**
- **Dense vector search (FAISS)** for semantic retrieval
- **Sparse keyword search (BM25)** for exact match queries
- **Graph-based retrieval (GraphRAG)** via scientific entity relationships
- A **Streamlit chatbot** interface powered by LLMs
- ğŸ”„ **Multi-turn conversational memory** for context-aware follow-up questions
- ğŸ“„ **Paper Summary Generator** to summarize full research papers into Abstract, Methods, Results, and Conclusion

â¡ï¸ Coming soon:

- ğŸ‘ **User feedback mode** for response rating
- ğŸ§  **FAISS metadata filtering** (e.g. by paper title)
- ğŸ•¸ï¸ **Named graphs/subgraph support** in GraphRAG
- ğŸ“Š **Cross-encoder-based reranking** for fusion pipelines
- **Docker Integration** for migration to different devices

---

## ğŸš¦ End-to-End Workflow Overview

```
[PDFs]
 â†“
chunking.py (semantic splitting)
 â†“
embedding.py â†’ FAISS index
       â†“
   bm25.py â†’ BM25 index (optional)
       â†“
graph_extraction.py + graph_builder.py â†’ GraphRAG (optional)
       â†“
RAG.py (retriever: faiss / bm25 / graphrag / hybrid)
 â†“
LLaMA 3.2 (via Ollama)
 â†“
Answer + References + Summary (optional)
```

---

## ğŸ“‚ Folder Structure & Key Files

| File/Folder           | Purpose                                          |
| --------------------- | ------------------------------------------------ |
| `chunking.py`         | Extract and intelligently chunk PDF text         |
| `embedding.py`        | Create vector embeddings using MiniLM            |
| `bm25.py`             | Create a sparse keyword search index             |
| `graph_extraction.py` | Extract triplets (subject, relation, object)     |
| `graph_builder.py`    | Build a directed graph from triplets             |
| `graph_retriever.py`  | Query neighbors/entities from the graph          |
| `RAG.py`              | RAG chatbot logic with retriever + LLM           |
| `config.py`           | Centralized config for paths and model names     |
| `main.py`             | Unified CLI for preprocessing and chatbot launch |
| `files/`              | Stores FAISS, BM25, Graph indexes and metadata   |

---

## ğŸš€ How to Use

### âœ… 1. Install Dependencies

```bash
pip install -r requirements.txt
```

---

### ğŸ§± 2. Preprocess the PDFs

This step:

- Reads all PDFs
- Chunks their text
- Generates embeddings for semantic retrieval (FAISS)
- (Optional) Creates BM25 index for exact keyword search
- (Optional) Extracts triplets and builds a GraphRAG knowledge graph
  - ğŸ”¬ Uses **BioNER-based entity extraction** for scientific concepts

#### â¤ Run FAISS-only pipeline:

```bash
python main.py --mode preprocess
```

#### â¤ Run FAISS + BM25 indexing:

```bash
python main.py --mode preprocess --use_bm25
```

#### â¤ Run FAISS + GraphRAG indexing:

```bash
python main.py --mode preprocess --use_graphrag
```

#### â¤ Run FAISS + BM25 + GraphRAG:

```bash
python main.py --mode preprocess --use_bm25 --use_graphrag
```

---

### ğŸ’¬ 3. Launch the Chatbot

You can choose **which retrieval mode to use**:

| Mode              | Description                                                           |
| ----------------- | --------------------------------------------------------------------- |
| `faiss` (default) | Dense semantic retrieval â€” great for paraphrased or long-form queries |
| `bm25`            | Sparse keyword match â€” great for exact phrases, chemical names        |
| `graphrag`        | Graph-based â€” queries related entities via knowledge triplets         |
| `faiss+graphrag`  | Combines FAISS + Graph for semantic + entity-grounded context         |
| `bm25+graphrag`   | Combines BM25 + Graph for keyword + entity retrieval                  |
| `hybrid`          | Combines FAISS + BM25 + Graph â€” best for comprehensive retrieval      |

#### â¤ Launch default (FAISS):

```bash
streamlit run main.py -- --mode chatbot
```

#### â¤ BM25 only:

```bash
streamlit run main.py -- --mode chatbot --retriever bm25
```

#### â¤ GraphRAG only:

```bash
streamlit run main.py -- --mode chatbot --retriever graphrag
```

#### â¤ FAISS + GraphRAG:

```bash
streamlit run main.py -- --mode chatbot --retriever faiss+graphrag
```

#### â¤ BM25 + GraphRAG:

```bash
streamlit run main.py -- --mode chatbot --retriever bm25+graphrag
```

#### â¤ Full hybrid (FAISS + BM25 + GraphRAG):

```bash
streamlit run main.py -- --mode chatbot --retriever hybrid
```

---

## ğŸ§  How Retrieval Works

### âœ… FAISS (Dense Semantic Retrieval)

- Uses `all-MiniLM-L6-v2` via `sentence-transformers`
- Captures meaning beyond keywords
- Great for paraphrased or long-form questions

### âœ… BM25 (Sparse Keyword Retrieval)

- Based on token overlap + frequency
- Ideal for exact matches, chemical names, acronyms

### âœ… GraphRAG (Knowledge Graph Retrieval)

- Uses `SciBERT` or `BioBERT` for **entity and triplet extraction**
- Entities are extracted using **transformer-based NER models** (e.g. `d4data/biomedical-ner-all`)
- Graph is constructed where nodes = entities and edges = contextual relationships from papers
- Supports multi-hop traversal for enhanced query matching

### âœ… Hybrid

- Combines top results from all retrievals
- Deduplicates context
- Ensures semantic + symbolic + lexical coverage

---

## ğŸ”§ Configuration

All file paths and model names are stored in:

```python
config.py
```

You can change:

- `RAW_PDF_DIR` â€” path to your academic PDFs
- `LLM_MODEL_NAME` â€” Ollama model to run (e.g. `llama3.2:latest`)
- `EMBEDDING_MODEL_NAME` â€” transformer model for embeddings
- `TRIPLET_MODEL_NAME` â€” SciBERT/BioBERT model for triplet extraction
- `NER_MODEL_NAME` â€” HuggingFace biomedical NER model
- `TAMU_LOGO_PATH`, `BACKGROUND_IMAGE_PATH` â€” Streamlit UI images

---

## ğŸ§  Key Features

- ğŸ—£ï¸ **Multi-turn conversational memory** â€” follow up with related questions
- ğŸ“„ **Paper summary generation** â€” extract insights by section (Abstract, Methods, etc.)
- ğŸ” Graph + BM25 + FAISS integration for **hybrid search**

â¡ï¸ **Planned Enhancements**:

- ğŸ‘ Feedback-based rating and evaluation logging
- ğŸ§  Metadata filtering during retrieval (e.g. per paper)
- ğŸ•¸ Named subgraph queries for thematic focus
- ğŸ“Š Fusion reranking with cross-encoders for better results

---

## ğŸ” Benefits of the System

- âš™ï¸ Fully modular (chunking, embedding, BM25, Graph, chatbot)
- ğŸ§  LLM-powered contextual answers
- ğŸ”Œ Easily swappable retrievers (FAISS, BM25, GraphRAG, Hybrid)
- ğŸš€ GPU-compatible for faster embeddings
- ğŸ–¼ï¸ Beautiful Streamlit UI
- ğŸ”„ Automatic Ollama startup if not running
- ğŸ”“ Designed to scale with future improvements

---

## ğŸ™Œ Credits & Tools Used

- FAISS â€” Dense vector search
- RankBM25 â€” Sparse keyword search
- NetworkX â€” Graph operations
- LangChain â€” LLM orchestration
- Ollama â€” Local LLM serving
- SentenceTransformers â€” Embeddings
- HuggingFace Transformers â€” BioNER, SciBERT for triplets

---

Built for deep, document-grounded academic question answering.  
_Query smarter, not harder_ ğŸ¤–ğŸ“˜âœ¨
